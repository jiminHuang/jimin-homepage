---
title: Neural sparse topical coding
publication_types:
  - "1"
authors:
  - Min Peng
  - Qianqian Xie*
  - Yanchun Zhang
  - Hua Wang
  - Xiuzhen Jenny Zhang
  - admin
  - Gang Tian
author_notes: []
doi: https://doi.org/10.18653/v1%2FP18-1217
publication: In *ACL*
publication_short: In *ACL(CCF-A)*
abstract: Topic models with sparsity enhancement have been proven to be
  effective at learning discriminative and coherent latent topics of short
  texts, which is critical to many scientific and engineering applications.
  However, the extensions of these models require carefully tailored graphical
  models and re-deduced inference algorithms, limiting their variations and
  applications. We propose a novel sparsity-enhanced topic model, Neural Sparse
  Topical Coding (NSTC) base on a sparsity-enhanced topic model called Sparse
  Topical Coding (STC). It focuses on replacing the complex inference process
  with the back propagation, which makes the model easy to explore extensions.
  Moreover, the external semantic information of words in word embeddings is
  incorporated to improve the representation of short texts. To illustrate the
  flexibility offered by the neural network based framework, we present three
  extensions base on NSTC without re-deduced inference algorithms. Experiments
  on Web Snippet and 20Newsgroups datasets demonstrate that our models
  outperform existing methods.
draft: false
featured: true
tags:
  - neural network
  - deep learning
  - topic model
  - neural topic model
  - sparse topic model
projects: []
image:
  filename: ""
  focal_point: Smart
  preview_only: false
summary: ""
date: 2018-07-01T06:13:00.846Z
---

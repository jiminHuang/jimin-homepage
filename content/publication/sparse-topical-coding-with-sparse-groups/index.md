---
title: Sparse topical coding with sparse groups
publication_types:
  - "1"
authors:
  - Min Peng
  - Qianqian Xie
  - Jiajia Huang
  - Jiahui Zhu
  - Shuang Ouyang
  - admin
  - Gang Tian
author_notes: []
doi: ""
publication: In *WAIM*
publication_short: ""
abstract: "Learning a latent semantic representing from a large number of short
  text corpora makes a profound practical significance in research and
  engineering. However, it is difficult to use standard topic models in
  microblogging environments since microblogs have short length, large amount,
  snarled noise and irregular modality characters, which prevent topic models
  from using full information of microblogs. In this paper, we propose a novel
  non-probabilistic topic model called sparse topical coding with sparse groups
  (STCSG), which is capable of discovering sparse latent semantic
  representations of large short text corpora. STCSG relaxes the normalization
  constraint of the inferred representations with sparse group lasso, a
  sparsity-inducing regularizer, which is convenient to directly control the
  sparsity of document, topic and word codes. Furthermore, the relaxed
  non-probabilistic STCSG can be effectively learned with alternating direction
  method of multipliers (ADMM). Our experimental results on Twitter dataset
  demonstrate that STCSG performs well in finding meaningful latent
  representations of short documents. Therefore, it can substantially improve
  the accuracy and efficiency of document classification. "
draft: false
featured: false
tags:
  - neural network
  - deep learning
  - topic model
  - neural topic model
  - sparse topic model
projects: []
image:
  filename: ""
  focal_point: Smart
  preview_only: false
summary: ""
date: 2016-06-03T06:50:56.150Z
---
